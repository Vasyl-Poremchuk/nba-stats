# NBA Stats

### The goal of the project is to collect and process NBA statistics from [Basketball Reference](https://www.basketball-reference.com/).

## Project Structure

- **Collectors**: Fetch HTML data from basketball-reference:
  - Seasons collector.
  - Leagues collector.
  - Teams collector.
  - Players collector.

- **Extractors**: Process raw HTML data into structured formats (parquet files):
  - Season data extractors.
  - Conference data extractors.
  - Team data extractors.
  - Player data extractors.

- **Infrastructure**: AWS resources (services) managed with Terraform:
  - S3 buckets for data storage and Terraform state file.
  - ECR repository for Docker images.
  - ECS with Fargate for task execution.
  - Lambda function to trigger ECS tasks.
  - EventBridge for scheduled execution (cron job).
  - CloudWatch for logging.

## Prerequisites

To use the project you must have:

- AWS account with appropriate permissions.
- Terraform installed locally for development.
- Docker installed locally for development.
- Python >= 3.12 and required libraries (see `requirements.txt`).
- GitHub account (for GitHub Actions CI/CD).

## Setup Instructions

### 1. Initial Setup

1. Clone this repository.
2. Create an AWS IAM role for GitHub Actions with appropriate permissions.
3. Add the following secrets to your GitHub repository:
   - `AWS_ROLE_TO_ASSUME`: ARN of the IAM role for GitHub Actions.
   - `VPC_ID`: ID of the VPC where the ECS tasks will run.
   - `SUBNET_ID`: ID of the subnet where the ECS tasks will run.

**NOTE**: For simplicity, `VPC_ID` and `SUBNET_ID` can be used as default values generated by AWS itself in your account.

### 2. Bootstrapping Infrastructure

1. Run the `Terraform Bootstrap` GitHub Actions workflow.
   - This creates the S3 bucket for Terraform state management.

### 3. Deploying Infrastructure

1. Run the `Deploy Infrastructure` GitHub Actions workflow.
   - This creates all AWS resources needed for the NBA data collection system.

### 4. Building & Pushing the Docker Image

1. Run the `Build & Push Docker Image` GitHub Actions workflow.
   - This builds the Docker image and pushes it to the ECR repository.

## Execution

The system is configured to run automatically once per year on May 1st (after the NBA season concludes).

## Development

### Running Locally

```bash
# Install dependencies.
pip install -r requirements.txt

# Run linter.
ruff check .

# Run tests.
pytest tests/

# Run the process.
python -m src.service
```

### Building Docker Image Locally

```bash
docker build -t nba-stats:latest .
```

### Running Docker Container Locally

```bash
docker run -d nba-stats:latest
```

## CI/CD Pipeline

The project uses GitHub Actions for CI/CD:

1. **Lint & Test**: Runs on every push.
2. **Terraform Bootstrap**: Manually triggered to set up Terraform backend.
3. **Deply Infrastructure**: Deploys or updates AWS infrastructure.
4. **Build & Push Docker Image**: Builds and pushed Docker image to ECR.

## License

This project is licensed under the Apache License 2.0 - see the `LICENSE` file for details.

## AWS Authentication

Use OpenID Connect within your workflows to authenticate with Amazon Web Services.

See the instructions on this [page](https://docs.github.com/en/actions/security-for-github-actions/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services) on how to achieve this.

## AWS Infrastructure

### Components

1. **Amazon ECR (Elastic Container Registry)**
   - Stores the Docker images of the NBA data collection project.
   - Configured with lifecycle policies to manage image versions.

2. **Amazon ECS (Elastic Container Service)**
   - Runs the containerized NBA data collections tasks.
   - Uses Fargate for serverless container execution without managing servers.
   - Defined task definitions specify CPU/memory resources.

**NOTE**: The default CPU and RAM for an ECS task are 4 vCPUs and 8 GB, respectively (see `terraform/variables.tf`).

3. **AWS Lambda**
   - Acts as a bridge between EventBridge and ECS.
   - Invokes the ECS task when triggered.
   - Handles error reporting and retries.

4. **Amazon EvenBridge**
   - Schedules the annual execution of the data collection process.
   - Configured to run on May 1st each year (after NBA season concludes).

5. **Amazon CloudWatch**
   - Collects and stores logs from all components.
   - Configured for long-term log retention (30 days.)

6. **Amazon S3**
   - Stores the Terraform state file.
   - Stores the processed NBA data in raw (HTML, JSON) and Parquet formats.
   - Organizes data by purpose (seasons, teams, players, etc.).
   - Implements versioning for data recovery.

## Project Architecture

The project follows a two-stage process:

1. **Collection Stage**
   - Downloads HTML data from basketball-reference.com.
   - Stores raw HTML files in a structured directory hierarchy.
   - Implemented in the `collectors` module.

2. **Extraction Stage**
   - Process raw HTML data into structured format (Parquet).
   - Implemented in the `extractors` module.

### Data Flow

```
Web Source -> Collectors -> Raw HTML -> Extractors -> Parquet Files -> S3 Storage
```

## CI/CD Pipeline

The CI/CD pipeline is implemented using GitHub Actions and consists of several workflows:

1. **Lint & Test**
   - Validate code quality and correctness.
   - Runs the Ruff linter and pytest tests.

2. **Terraform Bootstrap**
   - Sets up the Terraform backend (S3 bucket).
   - Runs only once during initial setup.

3. **Deploy Infrastructure**
   - Applies Terraform configurations to create/update AWS resources.
   - Triggered on changes to Terraform files or manually.

4. **Build & Push Docker Image**
   - Builds the application Docker image.
   - Pushes to ECR with versioned tags.
   - Triggered on code changes or manually.

## Security Considerations

1. **IAM Roles & Policies**
   - ECS task role with least-privilege permissions.
   - Lambda execution role with minimal permissions.

2. **Network Security**
   - ECS tasks run in private subnets with outbound-only access.
   - Security groups restrict traffic flow.

3. **Data Protection**
   - S3 bucket with server-side encryption.
   - Versioning enabled for data recovery.

4. **Secrets Management**
   - GitHub repository secrets for AWS credentials.
   - No hardcoded secrets in code or configurations.

## Monitoring & Logging

1. **CloudWatch Logs**
   - Centralized logging for all components.
   - Log retention configured for 30 days.

2. **CloudWatch Metrics**
   - Runtime metrics for Lambda and ECS.
   - S3 bucket metrics for storage utilization.

## Scaling Considerations

The system is designed to run once per year, but can be scaled if needed:

1. **Vertical Scaling**
   - Increase CPU/memory allocation for ECS tasks.

## Disaster Recovery

1. **S3 Versioning**
   - All data files are versioned for point-in-time recovery.

2. **Infrastructure as Code**
   - Complete infrastructure can be recreated using Terraform.

3. **Docker Images**
   - Tagged images in ECR provide application versioning.
